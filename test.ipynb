{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bb83b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(0, 17), match='The rain in Spain'>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "txt = \"The rain in Spain\"\n",
    "x = re.search(\"^The.*Spain$\", txt)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cafcc348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ceeb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a218db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_decode(content_bytes, encodings=('utf-8', 'latin-1', 'cp1252', 'iso-8859-1')):\n",
    "    \"\"\"\n",
    "    Try decoding bytes with multiple encodings.\n",
    "    Returns decoded content or None if all attempts fail.\n",
    "    \"\"\"\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return content_bytes.decode(encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "def read_file_with_fallback(filepath):\n",
    "    \"\"\"\n",
    "    Read a file with encoding fallback.\n",
    "    Returns content or None if decoding fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            content_bytes = f.read()\n",
    "        return try_decode(content_bytes)\n",
    "    except (IOError, UnicodeDecodeError):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "631dcc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_citations_from_bbl(bbl_content):\n",
    "    \"\"\"\n",
    "    Extract citations from .bbl file content.\n",
    "    Returns a list of cited paper titles.\n",
    "    \"\"\"\n",
    "    if not bbl_content:\n",
    "        return []\n",
    "\n",
    "    # Pattern to match complete bibitem entries including all content until next \\bibitem or \\end\n",
    "    pattern = r'\\\\bibitem(?:\\[[^\\]]*\\]){0,3}\\{[^\\}]*\\}(.*?)(?=\\\\bibitem|\\\\end\\{thebibliography\\})'\n",
    "    citations = []\n",
    "    \n",
    "    for match in re.finditer(pattern, bbl_content, re.DOTALL):\n",
    "        entry_content = match.group(1).strip()\n",
    "        \n",
    "        # Extract title from the first \\newblock (main title) or the first line if no \\newblock\n",
    "        title = None\n",
    "        newblock_match = re.search(r'\\\\newblock\\s*(.*?)(?=\\\\newblock|$)', entry_content, re.DOTALL)\n",
    "        if newblock_match:\n",
    "            title = newblock_match.group(1).strip()\n",
    "        else:\n",
    "            # Fallback: take first non-empty line\n",
    "            lines = [line.strip() for line in entry_content.split('\\n') if line.strip()]\n",
    "            if lines:\n",
    "                title = lines[0]\n",
    "        \n",
    "        if title:\n",
    "            # Clean up the title\n",
    "            # print(title)\n",
    "            title = re.sub(r'\\\\emph\\{([^}]*)\\}', r'\\1', title)  # Remove \\emph{}\n",
    "            title = re.sub(r'\\\\newblock', '', title)  # Remove \\newblock\n",
    "            title = re.sub(r'\\$.*?\\$', '', title)  # Remove math expressions\n",
    "            title = re.sub(r'\\\\[^\\s{}]*', '', title)  # Remove other LaTeX commands\n",
    "            title = re.sub(r'\\{|\\}', '', title)  # Remove curly braces\n",
    "            title = re.sub(r'\\s+', ' ', title).strip()  # Normalize whitespace\n",
    "            \n",
    "            # Remove common trailing punctuation and metadata\n",
    "            title = re.sub(r'\\.$', '', title)\n",
    "            title = re.sub(r'\\(Tech\\..*?\\)$', '', title).strip()\n",
    "            title = re.sub(r'\\(.*?\\)$', '', title).strip()\n",
    "            \n",
    "            if title:\n",
    "                # print(title)\n",
    "                citations.append(title)\n",
    "    \n",
    "    return citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec6d6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_citation_graph(dataset_path):\n",
    "    \"\"\"\n",
    "    Build a citation graph from the dataset.\n",
    "    Returns a networkx DiGraph and a title to paper_id mapping.\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    paper_id_counter = 0\n",
    "    title_to_id = {}\n",
    "    id_to_title = {}\n",
    "    id_to_folder = {}\n",
    "    problematic_files = []\n",
    "    l = 0\n",
    "    c = 0\n",
    "    # First pass: create nodes for all papers\n",
    "    for paper_folder in os.listdir(dataset_path):\n",
    "        l = l + 1\n",
    "        folder_path = os.path.join(dataset_path, paper_folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            title_path = os.path.join(folder_path, \"title.txt\")\n",
    "            title_content = read_file_with_fallback(title_path)\n",
    "            paper_id = -1\n",
    "            if title_content:\n",
    "                title = title_content.strip()\n",
    "                if title:\n",
    "                    if title in title_to_id:\n",
    "                        paper_id = title_to_id[title]\n",
    "                    else:\n",
    "                        paper_id = paper_id_counter\n",
    "                        title_to_id[title] = paper_id\n",
    "                        id_to_title[paper_id] = title\n",
    "                        id_to_folder[paper_id] = paper_folder\n",
    "                        G.add_node(paper_id, title=title, folder=paper_folder)\n",
    "                        paper_id_counter += 1\n",
    "                    for filename in os.listdir(folder_path):\n",
    "                        if filename.endswith('.bbl'):\n",
    "                            bbl_path = os.path.join(folder_path, filename)\n",
    "                            bbl_content = read_file_with_fallback(bbl_path)\n",
    "                            \n",
    "                            if bbl_content:\n",
    "                                cited_titles = extract_citations_from_bbl(bbl_content)\n",
    "                                \n",
    "                                for cited_title in cited_titles:\n",
    "                                    c += 1\n",
    "                                    if cited_title in title_to_id:\n",
    "                                        cited_id = title_to_id[cited_title]\n",
    "                                        G.add_edge(paper_id, cited_id)\n",
    "                                    else:\n",
    "                                        paper_id1 = paper_id_counter\n",
    "                                        title_to_id[cited_title] = paper_id1\n",
    "                                        id_to_title[paper_id1] = cited_title\n",
    "                                        G.add_node(paper_id1, title = cited_title, folder = paper_folder)\n",
    "                                        G.add_edge(paper_id, paper_id1)\n",
    "                                        paper_id_counter += 1\n",
    "                            else:\n",
    "                                problematic_files.append(bbl_path)\n",
    "\n",
    "            else:\n",
    "                problematic_files.append(title_path)\n",
    "    # Second pass: add edges based on citations\n",
    "    # print(\"number of titles: %d\", c)\n",
    "    # for paper_id, data in G.nodes(data=True):\n",
    "    #     paper_folder = data['folder']\n",
    "    #     folder_path = os.path.join(dataset_path, paper_folder)\n",
    "        \n",
    "    #     # Look for .bbl files in the folder\n",
    "    #     for filename in os.listdir(folder_path):\n",
    "    #         if filename.endswith('.bbl'):\n",
    "    #             bbl_path = os.path.join(folder_path, filename)\n",
    "    #             bbl_content = read_file_with_fallback(bbl_path)\n",
    "                \n",
    "    #             if bbl_content:\n",
    "    #                 cited_titles = extract_citations_from_bbl(bbl_content)\n",
    "                    \n",
    "    #                 for cited_title in cited_titles:\n",
    "    #                     if cited_title in title_to_id:\n",
    "    #                         cited_id = title_to_id[cited_title]\n",
    "    #                         G.add_edge(paper_id, cited_id)\n",
    "    #                     else:\n",
    "    #                         paper_id = paper_id_counter\n",
    "    #                         title_to_id[title] = paper_id\n",
    "    #                         id_to_title[paper_id] = title\n",
    "    #                         G.add_node(paper_id, title = cited_title)\n",
    "    #             else:\n",
    "    #                 problematic_files.append(bbl_path)\n",
    "    \n",
    "    # Write problematic files to a log\n",
    "    with open('problematic_files.log', 'w') as f:\n",
    "        f.write(\"Files that couldn't be decoded:\\n\")\n",
    "        f.write(\"\\n\".join(problematic_files))\n",
    "    \n",
    "    return G, title_to_id, id_to_title, id_to_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c941363",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_graph(G):\n",
    "    \"\"\"\n",
    "    Analyze the citation graph and print statistics.\n",
    "    \"\"\"\n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "    \n",
    "    # Calculate in-degree and out-degree statistics\n",
    "    in_degrees = [d for n, d in G.in_degree()]\n",
    "    out_degrees = [d for n, d in G.out_degree()]\n",
    "    \n",
    "    print(f\"Average in-degree: {sum(in_degrees)/len(in_degrees):.2f}\")\n",
    "    print(f\"Average out-degree: {sum(out_degrees)/len(out_degrees):.2f}\")\n",
    "    \n",
    "    # Number of isolated nodes (no citations in or out)\n",
    "    isolated = [n for n in G.nodes() if G.in_degree(n) == 0 and G.out_degree(n) == 0]\n",
    "    print(f\"Number of isolated nodes: {len(isolated)}\")\n",
    "    \n",
    "    # Plot degree distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(in_degrees, bins=50, log=True)\n",
    "    plt.title('In-degree Distribution (log scale)')\n",
    "    plt.xlabel('In-degree')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(out_degrees, bins=50, log=True)\n",
    "    plt.title('Out-degree Distribution (log scale)')\n",
    "    plt.xlabel('Out-degree')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('degree_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate weakly connected components (for diameter estimation)\n",
    "    if nx.is_weakly_connected(G):\n",
    "        print(\"Graph is weakly connected\")\n",
    "        try:\n",
    "            diameter = nx.diameter(G.to_undirected())\n",
    "            print(f\"Diameter of the graph: {diameter}\")\n",
    "        except:\n",
    "            print(\"Graph is too large to compute diameter directly\")\n",
    "    else:\n",
    "        print(\"Graph is not weakly connected\")\n",
    "        components = list(nx.weakly_connected_components(G))\n",
    "        print(f\"Number of weakly connected components: {len(components)}\")\n",
    "        largest_component = max(components, key=len)\n",
    "        print(f\"Size of largest component: {len(largest_component)}\")\n",
    "        \n",
    "        # Compute diameter of largest component\n",
    "        if len(largest_component) > 1:\n",
    "            subgraph = G.subgraph(largest_component).to_undirected()\n",
    "            try:\n",
    "                diameter = nx.diameter(subgraph)\n",
    "                print(f\"Diameter of largest component: {diameter}\")\n",
    "            except:\n",
    "                print(\"Largest component is too large to compute diameter directly\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df04a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.1\n"
     ]
    }
   ],
   "source": [
    "print(nx.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccf1c913",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = \"./dataset_papers\"  # Path to the extracted dataset\n",
    "    G, title_to_id, id_to_title, id_to_folder = build_citation_graph(dataset_path)\n",
    "    \n",
    "    # Save the graph using pickle (recommended for NetworkX 3.0+)\n",
    "    with open(\"citation_graph.gpickle\", \"wb\") as f:\n",
    "        pickle.dump(G, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    # Analyze the graph\n",
    "    # analyze_graph(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf605b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 144502\n",
      "Number of edges: 307962\n",
      "Average in-degree: 2.13\n",
      "Average out-degree: 2.13\n",
      "Number of isolated nodes: 143\n",
      "Graph is not weakly connected\n",
      "Number of weakly connected components: 198\n",
      "Size of largest component: 141979\n"
     ]
    }
   ],
   "source": [
    "analyze_graph(G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
